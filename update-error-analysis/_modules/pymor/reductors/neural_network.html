
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="indigo">
  <script src="../../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>pymor.reductors.neural_network &#8212; pyMOR vold_pymor+1358.g3807c667 Manual</title>
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/material.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/thebelab.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../../_static/pymor_favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />


  
   

<link rel="stylesheet" href="../../../_static/pymor.css"/>
  </head>
  <body dir=ltr
        data-md-color-primary=indigo data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/pymor/reductors/neural_network" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../../index.html" title="pyMOR vold_pymor+1358.g3807c667 Manual"
           class="md-header-nav__button md-logo">
          
              <img src="../../../_static/pymor_logo_white.svg" height="26"
                   alt="pyMOR vold_pymor+1358.g3807c667 Manual logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Documentation</span>
          <span class="md-header-nav__topic"> pymor.reductors.neural_network </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../../search.html" method="GET" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
      
  
  <script src="../../../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "/versions.json",
        target_loc = "../../../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../../../index.html" class="md-tabs__link">pyMOR vold_pymor+1358.g3807c667 Manual</a></li>
          <li class="md-tabs__item"><a href="../../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../../index.html" title="pyMOR vold_pymor+1358.g3807c667 Manual" class="md-nav__button md-logo">
      
        <img src="../../../_static/pymor_logo_white.svg" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../../../index.html"
       title="pyMOR vold_pymor+1358.g3807c667 Manual">Documentation</a>
  </label>
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="../../../getting_started.html" class="md-nav__link">Getting started</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../technical_overview.html" class="md-nav__link">Technical Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../environment.html" class="md-nav__link">Environment Variables</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../tutorials.html" class="md-nav__link">pyMOR Tutorials</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../release_notes.html" class="md-nav__link">Release Notes</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../bibliography.html" class="md-nav__link">Bibliography</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../generated/pymor.html" class="md-nav__link">pymor package</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../../generated/pymordemos.html" class="md-nav__link">pymordemos package</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-pymor-reductors-neural-network--page-root">Source code for pymor.reductors.neural_network</h1><div class="highlight"><pre>
<span></span><span class="c1"># This file is part of the pyMOR project (http://www.pymor.org).</span>
<span class="c1"># Copyright 2013-2020 pyMOR developers and contributors. All rights reserved.</span>
<span class="c1"># License: BSD 2-Clause License (http://opensource.org/licenses/BSD-2-Clause)</span>

<span class="kn">from</span> <span class="nn">pymor.core.config</span> <span class="kn">import</span> <span class="n">config</span>


<span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">HAVE_TORCH</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Number</span>

    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
    <span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
    <span class="kn">import</span> <span class="nn">torch.utils</span> <span class="k">as</span> <span class="nn">utils</span>

    <span class="kn">from</span> <span class="nn">pymor.algorithms.pod</span> <span class="kn">import</span> <span class="n">pod</span>
    <span class="kn">from</span> <span class="nn">pymor.core.base</span> <span class="kn">import</span> <span class="n">BasicObject</span>
    <span class="kn">from</span> <span class="nn">pymor.core.exceptions</span> <span class="kn">import</span> <span class="n">NeuralNetworkTrainingFailed</span>
    <span class="kn">from</span> <span class="nn">pymor.models.neural_network</span> <span class="kn">import</span> <span class="n">FullyConnectedNN</span><span class="p">,</span> <span class="n">NeuralNetworkModel</span><span class="p">,</span> <span class="n">NeuralNetworkInstationaryModel</span>


<div class="viewcode-block" id="NeuralNetworkReductor"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor">[docs]</a>    <span class="k">class</span> <span class="nc">NeuralNetworkReductor</span><span class="p">(</span><span class="n">BasicObject</span><span class="p">):</span>
        <span class="sd">"""Reduced Basis reductor relying on artificial neural networks.</span>

<span class="sd">        This is a reductor that constructs a reduced basis using proper</span>
<span class="sd">        orthogonal decomposition and trains a neural network that approximates</span>
<span class="sd">        the mapping from parameter space to coefficients of the full-order</span>
<span class="sd">        solution in the reduced basis.</span>
<span class="sd">        The approach is described in [HU18]_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fom</span>
<span class="sd">            The full-order |Model| to reduce.</span>
<span class="sd">        training_set</span>
<span class="sd">            Set of |parameter values| to use for POD and training of the</span>
<span class="sd">            neural network.</span>
<span class="sd">        validation_set</span>
<span class="sd">            Set of |parameter values| to use for validation in the training</span>
<span class="sd">            of the neural network.</span>
<span class="sd">        validation_ratio</span>
<span class="sd">            Fraction of the training set to use for validation in the training</span>
<span class="sd">            of the neural network (only used if no validation set is provided).</span>
<span class="sd">        basis_size</span>
<span class="sd">            Desired size of the reduced basis. If `None`, rtol, atol or l2_err must</span>
<span class="sd">            be provided.</span>
<span class="sd">        rtol</span>
<span class="sd">            Relative tolerance the basis should guarantee on the training set.</span>
<span class="sd">        atol</span>
<span class="sd">            Absolute tolerance the basis should guarantee on the training set.</span>
<span class="sd">        l2_err</span>
<span class="sd">            L2-approximation error the basis should not exceed on the training</span>
<span class="sd">            set.</span>
<span class="sd">        pod_params</span>
<span class="sd">            Dict of additional parameters for the POD-method.</span>
<span class="sd">        ann_mse</span>
<span class="sd">            If `'like_basis'`, the mean squared error of the neural network on</span>
<span class="sd">            the training set should not exceed the error of projecting onto the basis.</span>
<span class="sd">            If `None`, the neural network with smallest validation error is</span>
<span class="sd">            used to build the ROM.</span>
<span class="sd">            If a tolerance is prescribed, the mean squared error of the neural</span>
<span class="sd">            network on the training set should not exceed this threshold.</span>
<span class="sd">            Training is interrupted if a neural network that undercuts the</span>
<span class="sd">            error tolerance is found.</span>
<span class="sd">        """</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fom</span><span class="p">,</span> <span class="n">training_set</span><span class="p">,</span> <span class="n">validation_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">basis_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">l2_err</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">pod_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">ann_mse</span><span class="o">=</span><span class="s1">'like_basis'</span><span class="p">):</span>
            <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">validation_ratio</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">validation_set</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__auto_init</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>

<div class="viewcode-block" id="NeuralNetworkReductor.reduce"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor.reduce">[docs]</a>        <span class="k">def</span> <span class="nf">reduce</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="o">=</span><span class="s1">'[(N+P)*3, (N+P)*3]'</span><span class="p">,</span> <span class="n">activation_function</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
                   <span class="n">optimizer</span><span class="o">=</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span>
                   <span class="n">restarts</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
            <span class="sd">"""Reduce by training artificial neural networks.</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            hidden_layers</span>
<span class="sd">                Number of neurons in the hidden layers. Can either be fixed or</span>
<span class="sd">                a Python expression string depending on the reduced basis size</span>
<span class="sd">                `N` and the total dimension of the |Parameters| `P`.</span>
<span class="sd">            activation_function</span>
<span class="sd">                Activation function to use between the hidden layers.</span>
<span class="sd">            optimizer</span>
<span class="sd">                Algorithm to use as optimizer during training.</span>
<span class="sd">            epochs</span>
<span class="sd">                Maximum number of epochs for training.</span>
<span class="sd">            batch_size</span>
<span class="sd">                Batch size to use if optimizer allows mini-batching.</span>
<span class="sd">            learning_rate</span>
<span class="sd">                Step size to use in each optimization step.</span>
<span class="sd">            restarts</span>
<span class="sd">                Number of restarts of the training algorithm. Since the training</span>
<span class="sd">                results highly depend on the initial starting point, i.e. the</span>
<span class="sd">                initial weights and biases, it is advisable to train multiple</span>
<span class="sd">                neural networks by starting with different initial values and</span>
<span class="sd">                choose that one performing best on the validation set.</span>
<span class="sd">            seed</span>
<span class="sd">                Seed to use for various functions in PyTorch. Using a fixed seed,</span>
<span class="sd">                it is possible to reproduce former results.</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            rom</span>
<span class="sd">                Reduced-order |NeuralNetworkModel|.</span>
<span class="sd">            """</span>
            <span class="k">assert</span> <span class="n">restarts</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="k">assert</span> <span class="n">epochs</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="k">assert</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="k">assert</span> <span class="n">learning_rate</span> <span class="o">&gt;</span> <span class="mf">0.</span>

            <span class="c1"># set a seed for the PyTorch initialization of weights and biases and further PyTorch methods</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

            <span class="c1"># build a reduced basis using POD and compute training data</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'reduced_basis'</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reduced_basis</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_basis</span><span class="p">()</span>

            <span class="c1"># determine the numbers of neurons in the hidden layers</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">hidden_layers</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">,</span> <span class="p">{</span><span class="s1">'N'</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_basis</span><span class="p">),</span> <span class="s1">'P'</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">dim</span><span class="p">})</span>
            <span class="c1"># input and output size of the neural network are prescribed by the dimension of the parameter space</span>
            <span class="c1"># and the reduced basis size</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
            <span class="n">layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_layers_sizes</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">)</span>

            <span class="c1"># compute validation data</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'validation_data'</span><span class="p">):</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Computing validation snapshots ...'</span><span class="p">):</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_set</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_set</span><span class="p">:</span>
                            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_sample</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">mu</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_basis</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">number_validation_snapshots</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_ratio</span><span class="p">)</span>
                        <span class="c1"># randomly shuffle training data before splitting into two sets</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span>
                        <span class="c1"># split training data into validation and training set</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">number_validation_snapshots</span><span class="p">]</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="n">number_validation_snapshots</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span>

            <span class="c1"># run the actual training of the neural network</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Performing </span><span class="si">{</span><span class="n">restarts</span><span class="si">}</span><span class="s1"> restarts for training ...'</span><span class="p">):</span>

                <span class="k">for</span> <span class="n">run</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">restarts</span><span class="p">):</span>
                    <span class="n">neural_network</span><span class="p">,</span> <span class="n">current_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train</span><span class="p">(</span><span class="n">layers</span><span class="p">,</span> <span class="n">activation_function</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                                                       <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'losses'</span><span class="p">)</span> <span class="ow">or</span> <span class="n">current_losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="n">current_losses</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">neural_network</span> <span class="o">=</span> <span class="n">neural_network</span>

                        <span class="c1"># check if neural network is sufficient to guarantee certain error bounds</span>
                        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Checking tolerances for error of neural network ...'</span><span class="p">):</span>

                            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ann_mse</span><span class="p">,</span> <span class="n">Number</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="s1">'full'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ann_mse</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Aborting training after </span><span class="si">{</span><span class="n">run</span><span class="si">}</span><span class="s1"> restarts ...'</span><span class="p">)</span>
                                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_rom</span><span class="p">()</span>
                            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ann_mse</span> <span class="o">==</span> <span class="s1">'like_basis'</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="s1">'full'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_basis</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Aborting training after </span><span class="si">{</span><span class="n">run</span><span class="si">}</span><span class="s1"> restarts ...'</span><span class="p">)</span>
                                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_rom</span><span class="p">()</span>


            <span class="c1"># check if neural network is sufficient to guarantee certain error bounds</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Checking tolerances for error of neural network ...'</span><span class="p">):</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ann_mse</span><span class="p">,</span> <span class="n">Number</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="s1">'full'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">ann_mse</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">NeuralNetworkTrainingFailed</span><span class="p">(</span><span class="s1">'Could not train a neural network that '</span>
                                                      <span class="s1">'guarantees prescribed tolerance!'</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ann_mse</span> <span class="o">==</span> <span class="s1">'like_basis'</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="s1">'full'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_basis</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">NeuralNetworkTrainingFailed</span><span class="p">(</span><span class="s1">'Could not train a neural network with an error as small as the '</span>
                                                      <span class="s1">'reduced basis error! Maybe you can try a different neural '</span>
                                                      <span class="s1">'network architecture or change the value of `ann_mse`.'</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ann_mse</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'Using neural network with smallest validation error ...'</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Finished training with a validation loss of </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">[</span><span class="s2">"val"</span><span class="p">]</span><span class="si">}</span><span class="s1"> ...'</span><span class="p">)</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_rom</span><span class="p">()</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'Unknown value for mean squared error of neural network'</span><span class="p">)</span></div>

<div class="viewcode-block" id="NeuralNetworkReductor._compute_layers_sizes"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor._compute_layers_sizes">[docs]</a>        <span class="k">def</span> <span class="nf">_compute_layers_sizes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">):</span>
            <span class="sd">"""Compute the number of neurons in the layers of the neural network."""</span>
            <span class="k">return</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">parameters</span><span class="p">),]</span> <span class="o">+</span> <span class="n">hidden_layers</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_basis</span><span class="p">),]</span></div>

<div class="viewcode-block" id="NeuralNetworkReductor._build_rom"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor._build_rom">[docs]</a>        <span class="k">def</span> <span class="nf">_build_rom</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="sd">"""Construct the reduced order model."""</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Building ROM ...'</span><span class="p">):</span>
                <span class="n">rom</span> <span class="o">=</span> <span class="n">NeuralNetworkModel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neural_network</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">_reduced'</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">rom</span></div>

<div class="viewcode-block" id="NeuralNetworkReductor._train"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor._train">[docs]</a>        <span class="k">def</span> <span class="nf">_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">activation_function</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
            <span class="sd">"""Perform a single training iteration and return the resulting neural network."""</span>
            <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'training_data'</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'validation_data'</span><span class="p">)</span>

            <span class="c1"># LBFGS-optimizer does not support mini-batching, so the batch size needs to be adjusted</span>
            <span class="k">if</span> <span class="n">optimizer</span> <span class="o">==</span> <span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span><span class="p">))</span>

            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Training the neural network ...'</span><span class="p">):</span>

                <span class="c1"># initialize the neural network</span>
                <span class="n">neural_network</span> <span class="o">=</span> <span class="n">FullyConnectedNN</span><span class="p">(</span><span class="n">layers</span><span class="p">,</span>
                                                  <span class="n">activation_function</span><span class="o">=</span><span class="n">activation_function</span><span class="p">)</span><span class="o">.</span><span class="n">double</span><span class="p">()</span>

                <span class="c1"># initialize the optimizer</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">neural_network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                      <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

                <span class="n">loss_function</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
                <span class="n">early_stopping_scheduler</span> <span class="o">=</span> <span class="n">EarlyStoppingScheduler</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span><span class="p">))</span>

                <span class="c1"># create the training and validation sets as well as the respective data loaders</span>
                <span class="n">training_dataset</span> <span class="o">=</span> <span class="n">CustomDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span>
                <span class="n">validation_dataset</span> <span class="o">=</span> <span class="n">CustomDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span><span class="p">)</span>
                <span class="n">phases</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'train'</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">]</span>
                <span class="n">training_loader</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">training_dataset</span><span class="p">,</span>
                                                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="n">validation_loader</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">validation_dataset</span><span class="p">,</span>
                                                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="n">dataloaders</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'train'</span><span class="p">:</span>  <span class="n">training_loader</span><span class="p">,</span> <span class="s1">'val'</span><span class="p">:</span> <span class="n">validation_loader</span><span class="p">}</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'Starting optimization procedure ...'</span><span class="p">)</span>

                <span class="c1"># perform optimization procedure</span>
                <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                    <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'full'</span><span class="p">:</span> <span class="mf">0.</span><span class="p">}</span>

                    <span class="c1"># alternate between training and validation phase</span>
                    <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="n">phases</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
                            <span class="n">neural_network</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">neural_network</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

                        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

                        <span class="c1"># iterate over batches</span>
                        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                            <span class="n">inputs</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

                            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">):</span>
                                <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
                                    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_grad_enabled</span><span class="p">():</span>
                                        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">neural_network</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
                                    <span class="k">if</span> <span class="n">loss</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                                        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                                    <span class="k">return</span> <span class="n">loss</span>

                                <span class="c1"># perform optimization step</span>
                                <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
                                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

                                <span class="c1"># compute loss of current batch</span>
                                <span class="n">loss</span> <span class="o">=</span> <span class="n">closure</span><span class="p">()</span>

                            <span class="c1"># update overall absolute loss</span>
                            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

                        <span class="c1"># compute average loss</span>
                        <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

                        <span class="n">losses</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_loss</span>

                        <span class="n">losses</span><span class="p">[</span><span class="s1">'full'</span><span class="p">]</span> <span class="o">+=</span> <span class="n">running_loss</span>

                        <span class="c1"># check for early stopping</span>
                        <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">'val'</span> <span class="ow">and</span> <span class="n">early_stopping_scheduler</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="n">neural_network</span><span class="p">):</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">logging_disabled</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Early stopping training process after </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s1"> epochs ...'</span><span class="p">)</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">'Minimum validation loss: '</span>
                                                 <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">early_stopping_scheduler</span><span class="o">.</span><span class="n">best_losses</span><span class="p">[</span><span class="s2">"val"</span><span class="p">]</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
                            <span class="k">return</span> <span class="n">early_stopping_scheduler</span><span class="o">.</span><span class="n">best_neural_network</span><span class="p">,</span> <span class="n">early_stopping_scheduler</span><span class="o">.</span><span class="n">best_losses</span>

            <span class="k">return</span> <span class="n">early_stopping_scheduler</span><span class="o">.</span><span class="n">best_neural_network</span><span class="p">,</span> <span class="n">early_stopping_scheduler</span><span class="o">.</span><span class="n">best_losses</span></div>

<div class="viewcode-block" id="NeuralNetworkReductor.build_basis"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor.build_basis">[docs]</a>        <span class="k">def</span> <span class="nf">build_basis</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="sd">"""Compute a reduced basis using proper orthogonal decomposition."""</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Building reduced basis ...'</span><span class="p">):</span>

                <span class="c1"># compute snapshots for POD and training of neural networks</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Computing training snapshots ...'</span><span class="p">):</span>
                    <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">solution_space</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_set</span><span class="p">:</span>
                        <span class="n">U</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">mu</span><span class="p">))</span>

                <span class="c1"># compute reduced basis via POD</span>
                <span class="n">reduced_basis</span><span class="p">,</span> <span class="n">svals</span> <span class="o">=</span> <span class="n">pod</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">modes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_size</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rtol</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span>
                                           <span class="n">atol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">atol</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span> <span class="n">l2_err</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l2_err</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span>
                                           <span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pod_params</span> <span class="ow">or</span> <span class="p">{}))</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">mu</span><span class="p">,</span> <span class="n">u</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_set</span><span class="p">,</span> <span class="n">U</span><span class="p">):</span>
                    <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_sample</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">reduced_basis</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

            <span class="c1"># compute mean square loss</span>
            <span class="n">mean_square_loss</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">norm2</span><span class="p">())</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">svals</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">reduced_basis</span><span class="p">,</span> <span class="n">mean_square_loss</span></div>

<div class="viewcode-block" id="NeuralNetworkReductor._compute_sample"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor._compute_sample">[docs]</a>        <span class="k">def</span> <span class="nf">_compute_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">reduced_basis</span><span class="p">):</span>
            <span class="sd">"""Transform parameter and corresponding solution to tensors."""</span>
            <span class="c1"># determine the coefficients of the full-order solutions in the reduced basis to obtain the</span>
            <span class="c1"># training data; convert everything into tensors that are compatible with PyTorch</span>
            <span class="n">mu_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
            <span class="n">u_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">(</span><span class="n">reduced_basis</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">u</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">return</span> <span class="p">[(</span><span class="n">mu_tensor</span><span class="p">,</span> <span class="n">u_tensor</span><span class="p">),]</span></div>

<div class="viewcode-block" id="NeuralNetworkReductor.reconstruct"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkReductor.reconstruct">[docs]</a>        <span class="k">def</span> <span class="nf">reconstruct</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">):</span>
            <span class="sd">"""Reconstruct high-dimensional vector from reduced vector `u`."""</span>
            <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'reduced_basis'</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduced_basis</span><span class="o">.</span><span class="n">lincomb</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span></div></div>


<div class="viewcode-block" id="NeuralNetworkInstationaryReductor"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkInstationaryReductor">[docs]</a>    <span class="k">class</span> <span class="nc">NeuralNetworkInstationaryReductor</span><span class="p">(</span><span class="n">NeuralNetworkReductor</span><span class="p">):</span>
        <span class="sd">"""Reduced Basis reductor for instationary problems relying on</span>
<span class="sd">        artificial neural networks.</span>

<span class="sd">        This is a reductor that constructs a reduced basis using proper</span>
<span class="sd">        orthogonal decomposition and trains a neural network that approximates</span>
<span class="sd">        the mapping from parameter and time space to coefficients of the</span>
<span class="sd">        full-order solution in the reduced basis.</span>
<span class="sd">        The approach is described in [WHR19]_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fom</span>
<span class="sd">            The full-order |Model| to reduce.</span>
<span class="sd">        training_set</span>
<span class="sd">            Set of |parameter values| to use for POD and training of the</span>
<span class="sd">            neural network.</span>
<span class="sd">        validation_set</span>
<span class="sd">            Set of |parameter values| to use for validation in the training</span>
<span class="sd">            of the neural network.</span>
<span class="sd">        validation_ratio</span>
<span class="sd">            Fraction of the training set to use for validation in the training</span>
<span class="sd">            of the neural network (only used if no validation set is provided).</span>
<span class="sd">        basis_size</span>
<span class="sd">            Desired size of the reduced basis. If `None`, rtol, atol or l2_err must</span>
<span class="sd">            be provided.</span>
<span class="sd">        rtol</span>
<span class="sd">            Relative tolerance the basis should guarantee on the training set.</span>
<span class="sd">        atol</span>
<span class="sd">            Absolute tolerance the basis should guarantee on the training set.</span>
<span class="sd">        l2_err</span>
<span class="sd">            L2-approximation error the basis should not exceed on the training</span>
<span class="sd">            set.</span>
<span class="sd">        pod_params</span>
<span class="sd">            Dict of additional parameters for the POD-method.</span>
<span class="sd">        ann_mse</span>
<span class="sd">            If `'like_basis'`, the mean squared error of the neural network on</span>
<span class="sd">            the training set should not exceed the error of projecting onto the basis.</span>
<span class="sd">            If `None`, the neural network with smallest validation error is</span>
<span class="sd">            used to build the ROM.</span>
<span class="sd">            If a tolerance is prescribed, the mean squared error of the neural</span>
<span class="sd">            network on the training set should not exceed this threshold.</span>
<span class="sd">            Training is interrupted if a neural network that undercuts the</span>
<span class="sd">            error tolerance is found.</span>
<span class="sd">        """</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fom</span><span class="p">,</span> <span class="n">training_set</span><span class="p">,</span> <span class="n">validation_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">basis_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">l2_err</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">pod_params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">ann_mse</span><span class="o">=</span><span class="s1">'like_basis'</span><span class="p">):</span>
            <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">validation_ratio</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">validation_set</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__auto_init</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>

<div class="viewcode-block" id="NeuralNetworkInstationaryReductor._compute_layers_sizes"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkInstationaryReductor._compute_layers_sizes">[docs]</a>        <span class="k">def</span> <span class="nf">_compute_layers_sizes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">):</span>
            <span class="sd">"""Compute the number of neurons in the layers of the neural network</span>
<span class="sd">            (make sure to increase the input dimension to account for the time)."""</span>
            <span class="k">return</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,]</span> <span class="o">+</span> <span class="n">hidden_layers</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduced_basis</span><span class="p">),]</span></div>

<div class="viewcode-block" id="NeuralNetworkInstationaryReductor._build_rom"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkInstationaryReductor._build_rom">[docs]</a>        <span class="k">def</span> <span class="nf">_build_rom</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="sd">"""Construct the reduced order model."""</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Building ROM ...'</span><span class="p">):</span>
                <span class="n">rom</span> <span class="o">=</span> <span class="n">NeuralNetworkInstationaryModel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nt</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">neural_network</span><span class="p">,</span>
                                                     <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">_reduced'</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">rom</span></div>

<div class="viewcode-block" id="NeuralNetworkInstationaryReductor.build_basis"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkInstationaryReductor.build_basis">[docs]</a>        <span class="k">def</span> <span class="nf">build_basis</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="sd">"""Compute a reduced basis using proper orthogonal decomposition."""</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Building reduced basis ...'</span><span class="p">):</span>

                <span class="c1"># compute snapshots for POD and training of neural networks</span>
                <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="s1">'Computing training snapshots ...'</span><span class="p">):</span>
                    <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">solution_space</span><span class="o">.</span><span class="n">empty</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">mu</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_set</span><span class="p">:</span>
                        <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">'nt'</span><span class="p">):</span>
                            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">nt</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">nt</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
                        <span class="n">U</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

                <span class="c1"># compute reduced basis via POD</span>
                <span class="n">reduced_basis</span><span class="p">,</span> <span class="n">svals</span> <span class="o">=</span> <span class="n">pod</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">modes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_size</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rtol</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span>
                                           <span class="n">atol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">atol</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span> <span class="n">l2_err</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">l2_err</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span>
                                           <span class="o">**</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pod_params</span> <span class="ow">or</span> <span class="p">{}))</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">mu</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_set</span><span class="p">):</span>
                    <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_sample</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">U</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nt</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nt</span><span class="p">],</span> <span class="n">reduced_basis</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

            <span class="c1"># compute mean square loss</span>
            <span class="n">mean_square_loss</span> <span class="o">=</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">norm2</span><span class="p">())</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">svals</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">reduced_basis</span><span class="p">,</span> <span class="n">mean_square_loss</span></div>

<div class="viewcode-block" id="NeuralNetworkInstationaryReductor._compute_sample"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.NeuralNetworkInstationaryReductor._compute_sample">[docs]</a>        <span class="k">def</span> <span class="nf">_compute_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">reduced_basis</span><span class="p">):</span>
            <span class="sd">"""Transform parameter and corresponding solution to tensors</span>
<span class="sd">            (make sure to include the time instances in the inputs)."""</span>
            <span class="n">parameters_with_time</span> <span class="o">=</span> <span class="p">[</span><span class="n">mu</span><span class="o">.</span><span class="n">with_</span><span class="p">(</span><span class="n">t</span><span class="o">=</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fom</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nt</span><span class="p">)]</span>

            <span class="n">samples</span> <span class="o">=</span> <span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">(</span><span class="n">mu</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()),</span> <span class="n">torch</span><span class="o">.</span><span class="n">DoubleTensor</span><span class="p">(</span><span class="n">reduced_basis</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="n">u_t</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]))</span>
                       <span class="k">for</span> <span class="n">mu</span><span class="p">,</span> <span class="n">u_t</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parameters_with_time</span><span class="p">,</span> <span class="n">u</span><span class="p">)]</span>

            <span class="k">return</span> <span class="n">samples</span></div></div>


<div class="viewcode-block" id="EarlyStoppingScheduler"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.EarlyStoppingScheduler">[docs]</a>    <span class="k">class</span> <span class="nc">EarlyStoppingScheduler</span><span class="p">(</span><span class="n">BasicObject</span><span class="p">):</span>
        <span class="sd">"""Class for performing early stopping in training of neural networks.</span>

<span class="sd">        If the validation loss does not decrease over a certain amount of epochs, the</span>
<span class="sd">        training should be aborted to avoid overfitting the training data.</span>
<span class="sd">        This class implements an early stopping scheduler that recommends to stop the</span>
<span class="sd">        training process if the validation loss did not decrease by at least `delta`</span>
<span class="sd">        over `patience` epochs.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        size_training_validation_set</span>
<span class="sd">            Size of both, training and validation set together.</span>
<span class="sd">        patience</span>
<span class="sd">            Number of epochs of non-decreasing validation loss allowed, before early</span>
<span class="sd">            stopping the training process.</span>
<span class="sd">        delta</span>
<span class="sd">            Minimal amount of decrease in the validation loss that is required to reset</span>
<span class="sd">            the counter of non-decreasing epochs.</span>
<span class="sd">        """</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size_training_validation_set</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__auto_init</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">best_losses</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_neural_network</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

<div class="viewcode-block" id="EarlyStoppingScheduler.__call__"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.EarlyStoppingScheduler.__call__">[docs]</a>        <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">neural_network</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="sd">"""Returns `True` if early stopping of training is suggested.</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>
<span class="sd">            losses</span>
<span class="sd">                Dictionary of losses on the validation and the training set in</span>
<span class="sd">                the current epoch.</span>
<span class="sd">            neural_network</span>
<span class="sd">                Neural network that produces the current validation loss.</span>

<span class="sd">            Returns</span>
<span class="sd">            -------</span>
<span class="sd">            `True` if early stopping is suggested, `False` otherwise.</span>
<span class="sd">            """</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_losses</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_losses</span> <span class="o">=</span> <span class="n">losses</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_losses</span><span class="p">[</span><span class="s1">'full'</span><span class="p">]</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">size_training_validation_set</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_neural_network</span> <span class="o">=</span> <span class="n">neural_network</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta</span> <span class="o">&lt;=</span> <span class="n">losses</span><span class="p">[</span><span class="s1">'val'</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_losses</span> <span class="o">=</span> <span class="n">losses</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_losses</span><span class="p">[</span><span class="s1">'full'</span><span class="p">]</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">size_training_validation_set</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">best_neural_network</span> <span class="o">=</span> <span class="n">neural_network</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">return</span> <span class="kc">False</span></div></div>


<div class="viewcode-block" id="CustomDataset"><a class="viewcode-back" href="../../../generated/pymor.reductors.html#pymor.reductors.neural_network.CustomDataset">[docs]</a>    <span class="k">class</span> <span class="nc">CustomDataset</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="sd">"""Class that represents the dataset to use in PyTorch.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        training_data</span>
<span class="sd">            Set of training parameters and the respective coefficients of the</span>
<span class="sd">            solution in the reduced basis.</span>
<span class="sd">        """</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span> <span class="o">=</span> <span class="n">training_data</span>

        <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span>

        <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
            <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">t</span></div>
</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2013-2020 pyMOR developers and contributors.
              
          </div>
            Last updated on
              Dec 01, 2020.
            <br/>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 3.3.1.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>